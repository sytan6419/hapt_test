{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train:  11084\n",
      "Total Test:  5225\n"
     ]
    }
   ],
   "source": [
    "# Load LSTM network and generate text\n",
    "import sys\n",
    "import numpy\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout , BatchNormalization\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.layers import Reshape\n",
    "from keras.models import load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# load training data label in text form\n",
    "raw_train_label_text = open('train_label.txt', 'r', encoding='utf-8').read()\n",
    "raw_test_label_text =  open('test_label.txt', 'r', encoding='utf-8').read()\n",
    "\n",
    "# convert text to integer\n",
    "test_x = []\n",
    "train_x = []\n",
    "for _ in raw_train_label_text.splitlines():\n",
    "    val = int(_)\n",
    "    train_x.append(val)\n",
    "for _ in raw_test_label_text.splitlines():\n",
    "    val = int(_)\n",
    "    test_x.append(val)\n",
    "\n",
    "# summarize the loaded data\n",
    "train_count = len(train_x)\n",
    "test_count = len(test_x)\n",
    "print (\"Total Train: \", train_count)\n",
    "print (\"Total Test: \", test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_print_count(data, string='NA'):\n",
    "    unique, counts = np.unique(data, return_counts=True)\n",
    "    print(string)\n",
    "    print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11083, 1) (11083,)\n",
      "(5224, 1) (5224,)\n",
      "[b4]Train Y: \n",
      "{1: 1704, 2: 1606, 3: 1471, 4: 1672, 5: 1855, 6: 1820, 7: 148, 8: 110, 9: 172, 10: 161, 11: 214, 12: 150}\n",
      "[b4]Test Y: \n",
      "{1: 740, 2: 730, 3: 687, 4: 857, 5: 902, 6: 921, 7: 61, 8: 52, 9: 76, 10: 62, 11: 69, 12: 67}\n",
      "(11083, 1, 1) (11083, 12)\n",
      "(5224, 1, 1) (5224, 12)\n",
      "Correct guess:4675\n",
      "Accuracy = 89.49 %\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 1\n",
    "n_features = 1\n",
    "n_neurons = 50\n",
    "n_batch = 1\n",
    "n_outputs = 12\n",
    "\n",
    "# split into samples\n",
    "TrainX, trainy = split_sequence(train_x, n_steps)\n",
    "TestX, testy = split_sequence(test_x, n_steps)\n",
    "\n",
    "print(TrainX.shape, trainy.shape)\n",
    "print(TestX.shape, testy.shape)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "TrainX = TrainX.reshape((TrainX.shape[0], n_steps, n_features))\n",
    "TestX = TestX.reshape((TestX.shape[0], n_steps, n_features))\n",
    "\n",
    "debug_print_count(trainy, '[b4]Train Y: ')\n",
    "debug_print_count(testy, '[b4]Test Y: ')\n",
    "\n",
    "# one hot encode y\n",
    "trainy = to_categorical(trainy)\n",
    "testy = to_categorical(testy)\n",
    "\n",
    "# process to throw the first row\n",
    "trainy = trainy[:,1:13]\n",
    "testy = testy[:,1:13]\n",
    "    \n",
    "print(TrainX.shape, trainy.shape)\n",
    "print(TestX.shape, testy.shape)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    " \n",
    "# fit model\n",
    "#model.fit(TrainX, trainy, epochs=10, verbose=1, shuffle=False)\n",
    "#_, accuracy = model.evaluate(TestX, testy, batch_size=10, verbose=1)\n",
    "#print(\"Accuracy: {:.2f} %\".format(accuracy*100))\n",
    "# demonstrate prediction\n",
    "# fit network\n",
    "#for i in range(10):\n",
    "model.fit(TrainX, trainy, epochs=10, batch_size=n_batch, verbose=0, shuffle=False)\n",
    "model.reset_states()\n",
    "\n",
    "count = 0\n",
    "# online forecast\n",
    "for i in range(len(TestX)):\n",
    "    x, y = TestX[i], testy[i]\n",
    "    x = x.reshape((1, n_steps, n_features))\n",
    "    y_pred = model.predict(x, batch_size=1)\n",
    "    #print(y_pred)\n",
    "    y_predict = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(testy[i])\n",
    "    # add back the value to make sure activity label start from 1 instead of 0\n",
    "    y_predict = y_predict + 1\n",
    "    y = y + 1\n",
    "\n",
    "    #print('>Expected=%.1f, Predicted=%.1f' % (y, y_predict))\n",
    "    if (y == y_predict):\n",
    "        count+= 1\n",
    "#         print('>Expected=%.1f, Predicted=%.1f' % (y, y_predict))\n",
    "#     else:\n",
    "#          print('>Expected=%.1f, Predicted=%.1f' % (y, y_predict))\n",
    "    #print(\"Accuracy: {:.2f} %\".format(accuracy_score(testy, y_predict)*100))\n",
    "    #print(confusion_matrix(testy, y_predict))\n",
    "    #print(classification_report(testy, y_predict))\n",
    "else:\n",
    "    print(\"Correct guess:\" + str(count))\n",
    "    print(\"Accuracy = {:.2f} %\".format((count/len(TestX))*100))\n",
    "\n",
    "#print(confusion_matrix(testy, y_predict))\n",
    "#print(classification_report(testy, y_predict))\n",
    "#print(\"Accuracy: {:.2f} %\".format(accuracy_score(testy, y_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
