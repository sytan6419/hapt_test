{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "from sliding_window import sliding_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded number of sensor channels employed in the gyro X challenge - X,Y,Z\n",
    "SENSOR_CHANNELS = 3\n",
    "# Hardcoded number of classes in the gesture recognition problem\n",
    "NUM_CLASSES = 12\n",
    "# Hardcoded length of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "# Hardcoded step of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "\n",
    "# current path\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_group(dataset_type):\n",
    "    path = cwd+'/{}data.txt'.format(dataset_type)\n",
    "    data = load_file(path)\n",
    "    return data[:,0:3], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train')\n",
    "    print(\"Train set:\" + str(trainX.shape) + str(trainy.shape))\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test')\n",
    "    print(\"Test set:\" + str(testX.shape) + str(testy.shape))\n",
    "\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    _verbose, epochs, batch_size = 1, 10, 100\n",
    "    #n_timesteps, n_features, n_outputs = trainX.shape[0], trainX.shape[1], 12\n",
    "    n_timesteps, n_features, n_outputs = 24, 3, 12\n",
    "    print(n_timesteps, n_features, n_outputs)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=_verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=_verbose)\n",
    "    return accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:(273942, 3)(273942,)\n",
      "Test set:(125368, 3)(125368,)\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " ..after sliding and reshaping, train data: inputs (22827, 24, 3), targets (22827, 12)\n",
      " ..after sliding and reshaping, test data : inputs (10446, 24, 3), targets (10446, 12)\n",
      "24 3 12\n",
      "Epoch 1/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.7294 - accuracy: 0.3864\n",
      "Epoch 2/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.5398 - accuracy: 0.4556\n",
      "Epoch 3/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.4953 - accuracy: 0.4705\n",
      "Epoch 4/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.4604 - accuracy: 0.4828\n",
      "Epoch 5/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.4259 - accuracy: 0.5024\n",
      "Epoch 6/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.4008 - accuracy: 0.5061\n",
      "Epoch 7/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.3607 - accuracy: 0.5198\n",
      "Epoch 8/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.3367 - accuracy: 0.5284\n",
      "Epoch 9/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.3036 - accuracy: 0.5370\n",
      "Epoch 10/10\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 1.2869 - accuracy: 0.5437\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0491 - accuracy: 0.2443\n",
      ">#1: 24.430\n",
      "[24.430404603481293]\n",
      "Accuracy: 24.430% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy = load_dataset()\n",
    "\n",
    "    # Sensor data is segmented using a sliding window mechanism\n",
    "    trainX, trainy = opp_sliding_window(trainX, trainy, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "    testX, testy = opp_sliding_window(testX, testy, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "\n",
    "    # Data is reshaped\n",
    "    trainX = trainX.reshape((-1, SLIDING_WINDOW_LENGTH, SENSOR_CHANNELS)) # for input to Conv1D\n",
    "    testX = testX.reshape((-1, SLIDING_WINDOW_LENGTH, SENSOR_CHANNELS)) # for input to Conv1D\n",
    "\n",
    "    #convert data to categorical form [0 0 0 0 0 0 0 0 1 0 0 0 0]. Represent class in vector\n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    \n",
    "    print(trainy[0])\n",
    "    print(\" ..after sliding and reshaping, train data: inputs {0}, targets {1}\".format(trainX.shape, trainy.shape))\n",
    "    print(\" ..after sliding and reshaping, test data : inputs {0}, targets {1}\".format(testX.shape, testy.shape))\n",
    "\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
